{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Predicting the Price of Used Cars Using Machine Learning Algorithms\n",
    "<font color = 'Blue'> \n",
    "Names: Shin Le, Jeongyeon Kim, Benjamin Horvath, Nico Reategui, Paul Giglio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Report: https://docs.google.com/document/d/1zhQrkWmJjjMU6wIfBC78MygGzp-XUrkaUOWALfyAL9Q/edit\n",
    "\n",
    "Dataset: \n",
    "* https://www.kaggle.com/datasets/andreinovikov/used-cars-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Update:</b>\n",
    "\n",
    "* Our data now is in years (2009-2024) instead of (1995-2024) after dropped outliers.\n",
    "\n",
    "* We are building models now. \n",
    "Everything will be done soon. Please spend time to complete our final report. Feel free to try to complete any section in it. (the link above)\n",
    "\n",
    "* Our models are a little different from what we learned in class. Our project manipulates in Regression rather than Classification,\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a> <br>\n",
    "<font color = 'Blue'> \n",
    "# Table of Contents\n",
    "\n",
    "1. [About Dataset](#1)\n",
    "2. [Importing Libraries](#2)\n",
    "3. [Functions Implementation](#3)\n",
    "4. [Loading Data](#4)\n",
    "5. [Data Preprocessing](#5)\n",
    "6. [Exploratory Data Analysis (EDA)](#6)\n",
    "   1. [Filtering Data](#61)\n",
    "   2. [Detecting Outliers](#62)\n",
    "   3. [Labeling Encode](#63)\n",
    "   4. [Correlation Matrix](#64)\n",
    "7. [Data Splitting](#7)\n",
    "8. [Models Evaluations and Predictions](#8)\n",
    "   1. [*Full Model* with *Linear Regression*](#81)\n",
    "      1. [Using Sequential Feature Selection for the *Linear Regression*](#811)\n",
    "   2. [*Decision Tree*](#82)\n",
    "      1. [*A Pruned Tree*](#821)\n",
    "   3. [Ensemble Method: *Random Forest Regression*](#83)\n",
    "   4. [Ensemble Method: *Gradient Boosting Regression*](#84)\n",
    "   5. [*Support Vector Machine* (SVM)](#85)\n",
    "   6. [Comparing Models](#86)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<font color = 'blue'> \n",
    "## **1. About Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains data about 762,091 used cars scraped from cars.com. The data was collected on Apr, 2023.\n",
    "\n",
    "**Feature description**\n",
    "\n",
    "* manufacturer - name of the car manufacturer\n",
    "* model - name of the car model\n",
    "* year - the year when the car was produced\n",
    "* mileage - the number of miles the car has traveled since production\n",
    "* engine - car engine\n",
    "* transmission - type of the car's transmission\n",
    "* drivetrain - type of the car's drivetrain\n",
    "* fuel_type - type of fuel that the car consumes\n",
    "* mpg - the number of miles a car can travel using one gallon of fuel (miles per gallon)\n",
    "* exterior_color - car exterior color\n",
    "* interior_color - car interior color\n",
    "* accidents_or_damage - whether the car was involved in accidents\n",
    "* one_owner - whether the car was owned by one person\n",
    "* personal_use_only - whether the car was used only for personal purposes\n",
    "* seller_name - name of the seller\n",
    "* seller_rating - seller's rating\n",
    "* driver_rating - car rating given by drivers\n",
    "* driver_reviews_num - the number of car reviews left by drivers\n",
    "* price_drop - price reduction from the initial price\n",
    "* price - car price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "<font color = 'blue'> \n",
    "## **2. Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.pyplot import subplots\n",
    "\n",
    "#feature selection\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "#Metrics:\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "#Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import sklearn.model_selection as skm\n",
    "\n",
    "#tree\n",
    "from sklearn.tree import DecisionTreeRegressor,plot_tree ,export_text\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "#SVM\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder \n",
    "\n",
    "#searborn\n",
    "import seaborn as sns\n",
    "\n",
    "#splitting dataset into train and test data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "<font color = 'blue'> \n",
    "## **3. Functions Implementation**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### CORRELATION MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heat_map(data, var):\n",
    "    # Calculate the correlation matrix\n",
    "    correlation_matrix = data.corr()\n",
    "\n",
    "    # Create a figure with a specific size\n",
    "    plt.figure(figsize=(len(var) * 2, len(var) * 1.5))\n",
    "    \n",
    "    # Create a mask for the upper triangle to focus on the center\n",
    "    mask = np.triu(np.ones_like(correlation_matrix), k=0)\n",
    "\n",
    "    # Customize the color scale (cmap) to emphasize the center\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    # Increase the font size for annotations\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap=cmap, mask=mask,  vmin=-1, vmax=1, fmt=\".2f\", annot_kws={\"size\": 14})\n",
    "    plt.title('Correlation Heatmap')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "<font color = 'blue'> \n",
    "## **4. Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cars.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "<font color = 'blue'> \n",
    "## **5. Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "# Use str.extract to create new columns\n",
    "df[['Engine Displacement (L)', 'Engine Type', 'Engine Features']] = df['engine'].str.extract(r'(\\d+\\.\\d+)L\\s([A-Z0-9]+)\\s(.+)$')\n",
    "\n",
    "# Drop the original 'engine' column if you no longer need it\n",
    "df = df.drop(columns=['engine'])\n",
    "\n",
    "# Print the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Before handling data\n",
    "* Show the frequency for each column. This will initially show us the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df.columns.tolist():\n",
    "    print(f\"{df[feature].value_counts()}, \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "<font color = 'blue'> \n",
    "## **6. Exploratory Data Analysis (EDA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"61\"></a>\n",
    "<font color = 'blue'> \n",
    "### ***1. Filtering data***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Handle Missing value\n",
    "   * Price Column - Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before shrinkage\n",
    "mean_prices_by_year = df.groupby('year')['price'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mean_prices_by_year['year'], mean_prices_by_year['price'], marker='o', linestyle='-')\n",
    "plt.title('Average Price by year (before shrinking the range)')\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('Average Price')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Problem:</b>\n",
    "The original dataset has the abnormal Average Price in year 2009. So, we shrink the Price in the range (0,200000). This could a way to handle outliers. \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['price'].between(0,200000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Group by the 'year' column and calculate the Average Price for each year\n",
    "yearly_mean_prices = df.groupby('year')['price'].mean()\n",
    "\n",
    "# Fill NaN values in the 'price' column with the Average Price of their respective year\n",
    "df['price'].fillna(df['year'].map(yearly_mean_prices), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_prices_by_year = df.groupby('year')['price'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mean_prices_by_year['year'], mean_prices_by_year['price'], marker='o', linestyle='-')\n",
    "plt.title('Average Price by year (after shrinking the range)')\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('Average Price')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Mapping from long form to abbreviation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Drivetrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)\n",
    "\n",
    "# Create a mapping from long form to abbreviation\n",
    "drivetrain_mapping = {\n",
    "    'All-wheel Drive': 'AWD',\n",
    "    'Front-wheel Drive': 'FWD',\n",
    "    'Four-wheel Drive': '4WD',\n",
    "    'Rear-wheel Drive': 'RWD'\n",
    "}\n",
    "\n",
    "# Use the replace method to update the drivetrain column\n",
    "df['drivetrain'] = df['drivetrain'].replace(drivetrain_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* fuel_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)\n",
    "# Create a dictionary for mapping\n",
    "drivetrain_mapping = {\n",
    "    'Gasoline Fuel': 'Gasoline',\n",
    "    'Gas': 'Gasoline',\n",
    "    'Plug-In Hybrid': 'Hybrid',\n",
    "    'Hybrid Fuel': 'Hybrid',\n",
    "    'Gas/Electric Hybrid': 'Hybrid',\n",
    "    'Gasoline/Mild Electric Hybrid': 'Hybrid',\n",
    "    'Diesel Fuel': 'Diesel',\n",
    "    'Rear-wheel Drive': 'Electric',\n",
    "    'E85 Flex Fuel': 'Flex Fuel',\n",
    "    'Flex Fuel Capability': 'Flex Fuel'\n",
    "}\n",
    "\n",
    "# Use the replace method to update the drivetrain column\n",
    "df['fuel_type'] = df['fuel_type'].replace(drivetrain_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### Splitting `MPG` column into two separate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mpg'].fillna('0-0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the \"MPG Range\" into two columns\n",
    "df[['City MPG', 'Highway MPG']] = df['mpg'].str.split('-', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function to convert elements to int or replace with zero\n",
    "def convert_to_int_or_zero(value):\n",
    "    if isinstance(value, str):\n",
    "        # Remove non-numeric characters and try to convert to int\n",
    "        numeric_value = ''.join(filter(str.isdigit, value))\n",
    "        if numeric_value:\n",
    "            return int(numeric_value)\n",
    "    return 0\n",
    "\n",
    "# Apply the custom function to 'City MPG' and 'Highway MPG' columns\n",
    "df['City MPG'] = df['City MPG'].apply(convert_to_int_or_zero)\n",
    "df['Highway MPG'] = df['Highway MPG'].apply(convert_to_int_or_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \"N/A\" values with NaN\n",
    "df['City MPG'] .replace(0, np.nan, inplace=True)\n",
    "df['Highway MPG'].replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop('mpg', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mpg_histogram(df, str):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(df['City MPG'], bins=20, color='skyblue', edgecolor='black')\n",
    "    plt.title('City MPG Histogram '+str+' Replacing NAN')\n",
    "    plt.xlabel('City MPG')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(df['Highway MPG'], bins=20, color='lightcoral', edgecolor='black')\n",
    "    plt.title('Highway MPG Histogram '+str+' Replacing NAN')\n",
    "    plt.xlabel('Highway MPG')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the histograms\n",
    "    plt.show()\n",
    "    \n",
    "create_mpg_histogram(df, 'Before')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### **Replace `NAN` in '`City MPG`' and '`Highway MPG`' by the `Mean` of each column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['City MPG'] .replace(np.nan,df['City MPG'].mean(), inplace=True)\n",
    "df['Highway MPG'].replace(np.nan,df['Highway MPG'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_mpg_histogram(df, 'After')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop('price_drop', axis=1)       #Drop this column since it does not provide useful information and has a lot of null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### **Handling `NAN` in `seller_rating`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_seller_rating_histograms(df, str):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(df['seller_rating'], bins=20, color='skyblue', edgecolor='black')\n",
    "    plt.title('seller_rating Histogram '+str+' Replacing NAN')\n",
    "    plt.xlabel('seller_rating')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the histograms\n",
    "    plt.show()\n",
    "    \n",
    "create_seller_rating_histograms(df, 'Before')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['seller_rating'].replace(np.nan,df['seller_rating'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_seller_rating_histograms(df, 'After')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() # Checking null values on each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use value_counts to count the frequency of each Engine Type\n",
    "engine_type_counts = df['Engine Features'].value_counts()\n",
    "\n",
    "# Get the top 20 values with the highest frequency\n",
    "top_20_engine_types = engine_type_counts.head(40)\n",
    "\n",
    "# Print the top 20 values and their frequencies\n",
    "print(top_20_engine_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have a lot of null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* #### ...after filtering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df.columns.tolist():\n",
    "    print(f\"{df[feature].value_counts()}, \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() #shows a summary of our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check and drop **Null** values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is null value in **fuel_consumption_g_km** column. So, we need to drop these before using it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check and drop duplicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set after cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Counting the data for each feature:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the presence of outliers, and the data spans a wide range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"62\"></a>\n",
    "<font color = 'blue'> \n",
    "### **2. Detecting outliers**\n",
    "* #### **For numerical columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "#numerical_cols.remove()\n",
    "num_columns=df[numerical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Average Price by year with outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b>  This method is just applied for <b>numerical features</b>. <br>\n",
    "There is no specific way to detect outlier for <b>categorical columns</b>. We can plot the Frequency vs Price for each categorical columns, and then decide the outliers depend on the frequency.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_prices_by_year = df.groupby('year')['price'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mean_prices_by_year['year'], mean_prices_by_year['price'], marker='o', linestyle='-')\n",
    "plt.title('Average Price by year (before removed outliers)')\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('Average Price')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in 2009, the price was so abnormal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = num_columns[numerical_cols].quantile(0.25)\n",
    "Q3 = num_columns[numerical_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers and create a boolean mask\n",
    "outliers_mask = (num_columns[numerical_cols] < lower_bound) | (num_columns[numerical_cols] > upper_bound)\n",
    "\n",
    "# Drop the rows containing outliers\n",
    "num_columns = num_columns[~outliers_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is new numerical columns after removed the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_num_columns= num_columns.dropna() #drop the rows which are contain NAN \n",
    "new_num_columns.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot Average Price vs Years ((after removed outliers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_prices_by_year = num_columns.groupby('year')['price'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mean_prices_by_year['year'], mean_prices_by_year['price'], marker='o', linestyle='-')\n",
    "plt.title('Average Price by year (after removed outliers)')\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('Average Price')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"\"></a>\n",
    "<font color = 'blue'>\n",
    "* ### **For categorical columns:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to plot them vs Price to see the pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Drop 'model', 'seller_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['model', 'seller_name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns= df.select_dtypes(include=['object']).columns.tolist()\n",
    "#these are the columns that we need to plot to detect the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[~df['transmission'].isin(['Unknown', 'Semi-automatic'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical_feature(cat_columns,df):\n",
    "    fig = plt.figure(figsize=(6, 6 * len(cat_columns)))\n",
    "\n",
    "    for j, cat_feature in enumerate(cat_columns):\n",
    "        ax = fig.add_subplot(len(cat_columns), 1, j+1)\n",
    "        df[cat_feature].value_counts().plot(ax=ax, kind='bar')\n",
    "        ax.set_xlabel(cat_feature)\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title(cat_feature)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "# plot categorical features to detect and remove outliers\n",
    "plot_categorical_feature(cat_columns,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Drivetrain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['drivetrain'].isin(['FWD', 'AWD', '4WD', 'RWD'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Fuel_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['fuel_type'].isin(['Compressed Natural Gas', 'Bio Diesel', 'Automatic'   ])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We just keep top 20 classes which are the most common in `exterior_color`, `interior_color`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df['exterior_color'].value_counts()\n",
    "# Get the top 20 most frequent classes\n",
    "top_20_classes = value_counts.index[:20]\n",
    "# Filter the DataFrame to keep rows in the top 20 classes\n",
    "df = df[df['exterior_color'].isin(top_20_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df['interior_color'].value_counts()\n",
    "# Get the top 20 most frequent classes\n",
    "top_20_classes = value_counts.index[:20]\n",
    "# Filter the DataFrame to keep rows in the top 20 classes\n",
    "df = df[df['interior_color'].isin(top_20_classes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Engine Displacement (L)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df['Engine Displacement (L)'].value_counts()\n",
    "# Get the top 30 most frequent classes\n",
    "top_30_classes = value_counts.index[:30]\n",
    "# Filter the DataFrame to keep rows in the top 30 classes\n",
    "df = df[df['Engine Displacement (L)'].isin(top_30_classes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Engine Type` (top 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df['Engine Type'].value_counts()\n",
    "# Get the top 10 most frequent classes\n",
    "top_10_classes = value_counts.index[:10]\n",
    "# Filter the DataFrame to keep rows in the top 10 classes\n",
    "df = df[df['Engine Type'].isin(top_10_classes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Engine Features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df['Engine Features'].value_counts()\n",
    "# Get the top 20 most frequent classes\n",
    "top_20_classes = value_counts.index[:20]\n",
    "# Filter the DataFrame to keep rows in the top 20 classes\n",
    "df = df[df['Engine Features'].isin(top_20_classes)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We just keep top 20 classes which are the most popular in `Transmission`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the value counts for the 'transmission' column\n",
    "value_counts = df['transmission'].value_counts()\n",
    "\n",
    "# Get the top 20 most frequent classes\n",
    "top_20_classes = value_counts.index[:20]\n",
    "\n",
    "# Filter the DataFrame to keep rows with 'transmission' in the top 20 classes\n",
    "df = df[df['transmission'].isin(top_20_classes)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot after cleaning data\n",
    "plot_categorical_feature(cat_columns,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data =df.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = pd.concat([new_num_columns, cat_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df= cleaned_df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_year_vs_price(df):\n",
    "    mean_prices_by_year = df.groupby('year')['price'].mean().reset_index()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(mean_prices_by_year['year'], mean_prices_by_year['price'], marker='o', linestyle='-')\n",
    "    plt.title('Average Price by year (before shrinking the range)')\n",
    "    plt.xlabel('year')\n",
    "    plt.ylabel('Average Price')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_year_vs_price(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"63\"></a>\n",
    "<font color = 'blue'>\n",
    "### **3. Labeling Encode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_columns= cleaned_df.select_dtypes(include=['object']).columns.tolist()\n",
    "# Create a LabelEncoder instance\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode each categorical column\n",
    "for col in cat_columns:\n",
    "    cleaned_df[col] = label_encoder.fit_transform(cleaned_df[col])\n",
    "\n",
    "# Your DataFrame now contains the encoded values\n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df['accidents_or_damage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df=cleaned_df.drop(['accidents_or_damage'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"64\"></a>\n",
    "<font color = 'blue'>\n",
    "### **4. Correlation Matrix**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **`correlation matrix`** shows us the correlation coefficients between variables. \n",
    "* If the correlation coefficient is close to 1, it appears a strong positive relationship. That means, if one variable increases, the other tends to increase as well.\n",
    "* If the correlation coefficient is close to -1, it appears a strong negative relationship. That means, if one variable decreases, the other tends to decrease as well.\n",
    "* If the correlation coefficient is close to 0, it appears a weak or no linear relationship between two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map(cleaned_df, cleaned_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> <b>Tip:</b> We can see there are some correlated features. We need to select the useful feature carefully to get optimize our model as much as possible </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target is `Price`, which is strong relationship to many features. However, the variables outside our target exhibit multicollinearity, such as: City MPG - Highway MPG, year-one owner, and Engine features-Engine Type, Engine Displacement(L), Engine Type, City, Highway MPG, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use **`variance_inflation_factor`** to diagnose the multicollinearity. Typically, a high VIF value (usually greater than 10) is an indicator of significant multicollinearity. It means that the variance of the coefficient estimate for that variable is 10 times larger than it would be if there were no multicollinearity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library for VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calc_vif(x):\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = x.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(x.values, i) for i in range(x.shape[1])]\n",
    "    return vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's  drop some features: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=cleaned_df.drop(['Engine Type', 'Engine Features','City MPG','interior_color', 'personal_use_only', 'driver_rating','seller_rating'], axis =1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map(df2, cleaned_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_vif(df2.drop('price', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the important features that we will use to fit our models:\n",
    "**year,\n",
    "mileage\t,\n",
    "one_owner\t,\n",
    "driver_reviews_num,\t\n",
    "Highway MPG\t,\n",
    "manufacturer,\t\n",
    "transmission,\t\n",
    "drivetrain,\t\n",
    "fuel_type,\t\n",
    "exterior_color,\t\n",
    "Engine Displacement (L),** in dataframe `df2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "<font color = 'blue'>\n",
    "## **7. Data Splitting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.drop('price', axis =1)\n",
    "Y= df2['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a>\n",
    "<font color = 'blue'>\n",
    "## **8. Models Evaluations and Predictions**\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"81\"></a>\n",
    "<font color = 'blue'>\n",
    "### **8.1 Multiple Linear Regression**\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"811\"></a>\n",
    "<font color = 'blue'>\n",
    "* #### **8.1.1. Using Sequential Feature Selection for the Linear Regression**\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the **Sequential Feature Selection** method to choose 10-15 significant variables for our model.\n",
    "\n",
    "Learn more: [Sequential Feature Selection](https://scikit-learn.org/stable/modules/feature_selection.html#removing-features-with-low-variance) (Forward/ Backward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg=Lasso(fit_intercept= True, random_state = random_state)\n",
    "sfs = SequentialFeatureSelector(lasso_reg, direction ='forward',  n_features_to_select=8).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features=sfs.get_feature_names_out()\n",
    "best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map(df2, best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We will use these features to fit our models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(columns=['Model', 'MAE', 'MSE', 'R2']) # these metrics are used to evaluate our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train[best_features]\n",
    "X_test=X_test[best_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LinearRegression(fit_intercept=True)\n",
    "LR.fit(X_train, y_train)\n",
    "y_pred = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Model 1 MAE:\", mae)\n",
    "print(\"Model 1 MSE:\", mse)\n",
    "print(\"Model 1 R2:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant term to your X_train (if not already included) for the intercept\n",
    "X_train1 = sm.add_constant(X_train)\n",
    "\n",
    "# Create a linear regression model\n",
    "model = sm.OLS(y_train, X_train1)\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Display the summary\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already fitted your linear regression model and have predictions\n",
    "# Create a scatterplot of fitted values vs. residuals\n",
    "residuals = y_test - y_pred  # Calculate the residuals\n",
    "\n",
    "# Create a scatterplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.title('Residuals vs. Fitted Values')\n",
    "plt.xlabel('Fitted Values')\n",
    "plt.ylabel('Residuals')\n",
    "\n",
    "# Add a horizontal line at y=0 for reference\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that there may be a **violation of the assumption of linearity** in our linear regression model. This pattern suggests that the relationship between the independent variables (**features**) and the dependent variable (`price`) is not adequately captured by a simple linear model.\n",
    "\n",
    "So, we need to try **polynomial regression**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING ERROR PER DEGREE\n",
    "train_rmse_errors = []\n",
    "# TEST ERROR PER DEGREE\n",
    "test_rmse_errors = []\n",
    "#MODEL and METRIC COLLECTION\n",
    "model_collection =[]\n",
    "mae_collection =[]\n",
    "mse_collection =[]\n",
    "r2_collection  =[]\n",
    "y_test_collection=[]\n",
    "\n",
    "for d in range(1,5):\n",
    "    # CREATE POLY DATA SET FOR DEGREE \"d\"\n",
    "    polynomial_converter = PolynomialFeatures(degree=d,include_bias=False)\n",
    "    poly_features = polynomial_converter.fit_transform(X)\n",
    "\n",
    "    # SPLIT THIS NEW POLY DATA SET\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(poly_features, Y, test_size=0.3, random_state=random_state)\n",
    "\n",
    "    # TRAIN ON THIS NEW POLY SET\n",
    "    model = LinearRegression(fit_intercept=True)\n",
    "    model.fit(X_train1,y_train1)\n",
    "    model_collection.append(model)\n",
    "\n",
    "    # PREDICT ON BOTH TRAIN AND TEST\n",
    "    train_pred = model.predict(X_train1)\n",
    "    test_pred = model.predict(X_test1)\n",
    "    y_test_collection.append(test_pred)\n",
    "    \n",
    "    # Calculate Errors\n",
    "\n",
    "    # Errors on Train Set\n",
    "    train_RMSE = np.sqrt(mean_squared_error(y_train1,train_pred))\n",
    "\n",
    "    # Errors on Test Set\n",
    "    test_RMSE = np.sqrt(mean_squared_error(y_test1,test_pred))\n",
    "\n",
    "    # Append errors to lists for plotting later\n",
    "    mae_collection.append( mean_absolute_error(y_test1, test_pred))\n",
    "    mse_collection.append( mean_squared_error(y_test1, test_pred))\n",
    "    r2_collection .append( r2_score(y_test1, test_pred))\n",
    "\n",
    "    train_rmse_errors.append(train_RMSE)\n",
    "    test_rmse_errors.append(test_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the RMSE values for degrees 1, 2,3,4\n",
    "plt.plot(range(1, 5), train_rmse_errors[:5], label='TRAIN')\n",
    "plt.plot(range(1, 5), test_rmse_errors[:5], label='TEST')\n",
    "plt.xlabel(\"Polynomial Complexity\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_collection)\n",
    "print(mae_collection )\n",
    "print(mse_collection )\n",
    "print(r2_collection  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the **polynomial degree 3** could be **the best** since the test error start overfitting at or after degree 4.\n",
    "So, let create and refit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_degree_index = 3-1\n",
    "mae =mae_collection[best_degree_index]\n",
    "mse = mse_collection[best_degree_index]\n",
    "r2 =r2_collection[best_degree_index]\n",
    "\n",
    "print(\"The Polynomial Regression Model MAE:\", mae)\n",
    "print(\"Polynomial Regression Model MSE:\", mse)\n",
    "print(\"Polynomial Regression Model R2:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append metrics to the DataFrame\n",
    "metrics_df = metrics_df.append({'Model': f'Degree {best_degree_index+1} Polynomial Regression', 'MAE': mae, 'MSE': mse, 'R2': r2}, ignore_index=True)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=y_test_collection[best_degree_index]\n",
    "# Calculate the residuals\n",
    "residuals_poly = y_test1 - y_pred\n",
    "\n",
    "# Create a scatterplot of fitted values vs. residuals\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(test_pred, residuals_poly, alpha=0.5)\n",
    "plt.title('Residuals vs. Fitted Values (Polynomial Regression)')\n",
    "plt.xlabel('Fitted Values (Polynomial Regression)')\n",
    "plt.ylabel('Residuals')\n",
    "\n",
    "# Add a horizontal line at y=0 for reference\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the plot does not appear a pattern. That means, there is a linear relationship among variables in polynomial regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of degrees for the x-axis (you can adjust this as needed)\n",
    "degrees = [1, 2, 3, 4]  \n",
    "\n",
    "# Create a figure with three subplots\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Create a scatter plot for MAE\n",
    "ax1.plot(degrees, mae_collection, label='MAE', marker='o', linestyle='-')\n",
    "ax1.set_xlabel(\"Polynomial Degree\")\n",
    "ax1.set_ylabel(\"MAE\")\n",
    "ax1.set_title(\"MAE vs. Polynomial Degree\")\n",
    "ax1.grid(True)\n",
    "\n",
    "# Create a scatter plot for MSE\n",
    "ax2.plot(degrees, mse_collection, label='MSE', marker='x', linestyle='-')\n",
    "ax2.set_xlabel(\"Polynomial Degree\")\n",
    "ax2.set_ylabel(\"MSE\")\n",
    "ax2.set_title(\"MSE vs. Polynomial Degree\")\n",
    "ax2.grid(True)\n",
    "\n",
    "# Create a scatter plot for R2\n",
    "ax3.plot(degrees, r2_collection, label='R2', marker='s', linestyle='-')\n",
    "ax3.set_xlabel(\"Polynomial Degree\")\n",
    "ax3.set_ylabel(\"R2\")\n",
    "ax3.set_title(\"R2 vs. Polynomial Degree\")\n",
    "ax3.grid(True)\n",
    "\n",
    "# Add a legend to one of the subplots\n",
    "ax1.legend()\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"82\"></a>\n",
    "<font color = 'blue'>\n",
    "   ### **8.2 Decision Tree**\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"821\"></a>\n",
    "<font color = 'blue'>\n",
    "* #### **8.2.1. A Pruned Tree**: Pruning reduces the size of decision trees by removing parts of the tree that do not provide power to classify instances. Decision trees are the most susceptible out of all the machine learning algorithms to overfitting and effective pruning can reduce this likelihood.\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_churn_tree = DecisionTreeRegressor(criterion='absolute_error',max_depth=4)\n",
    "#best_churn_tree = DecisionTreeRegressor(criterion='absolute_error',max_depth=5, min_samples_split=10)\n",
    "\n",
    "best_churn_tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = best_churn_tree.predict(X_test)\n",
    "score = mean_absolute_error(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ccp_path = best_churn_tree.cost_complexity_pruning_path(X_train, y_train)\n",
    "kfold = skm.KFold(5,random_state=0,shuffle=True)\n",
    "\n",
    "grid = skm.GridSearchCV(best_churn_tree,{'ccp_alpha': ccp_path.ccp_alphas},refit=True,cv=kfold, n_jobs=-1,scoring='neg_mean_absolute_error',return_train_score=True) \n",
    "grid.fit(X_train, y_train)\n",
    "print(f\"Best Cross-Validation Score: {grid.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = grid.best_estimator_ \n",
    "print(best_tree)\n",
    "print(f\"Best Tree Depth: {best_tree.get_depth()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision tree with clearer visualization\n",
    "plt.figure(figsize=(25, 20))  # Adjust the figure size\n",
    "\n",
    "plot_tree(\n",
    "    best_tree,\n",
    "    filled=True,  # Fill nodes with color\n",
    "    feature_names=X_train.columns,  # Provide feature names for labeling\n",
    "    fontsize=8,  # Adjust font size\n",
    ")\n",
    "\n",
    "plt.title(\"Car Price Prediction - Decision Tree\")\n",
    "plt.show()\n",
    "print(export_text(best_tree,feature_names=list(X_train.columns),show_weights=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=best_tree.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append metrics to the DataFrame\n",
    "metrics_df = metrics_df.append({'Model': type(best_tree).__name__, 'MAE': mae, 'MSE': mse, 'R2': r2}, ignore_index=True)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"83\"></a>\n",
    "<font color = 'blue'>\n",
    "### **8.3. Ensemble Method: Random Forest Regression**\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'bootstrap': [True],'n_estimators':[ 100], \"max_depth\":[4], 'criterion': ['squared_error']}\n",
    "kfold = skm.KFold(5,random_state=0,shuffle=True)\n",
    "grid_search = skm.GridSearchCV(RandomForestRegressor( random_state=0,n_jobs = -1),param_grid, cv=kfold,return_train_score=True,scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Fit the grid search to your data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append metrics to the DataFrame\n",
    "metrics_df = metrics_df.append({'Model': type(model).__name__, 'MAE': mae, 'MSE': mse, 'R2': r2}, ignore_index=True)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"84\"></a>\n",
    "<font color = 'blue'>\n",
    "   ### **8.4. Ensemble Method: Gradient Boosting Regression**\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'learning_rate': [0.1],'n_estimators':[ 100], \"max_depth\":[4], 'criterion': ['squared_error']}\n",
    "kfold = skm.KFold(5,random_state=0,shuffle=True)\n",
    "grid_search = skm.GridSearchCV(GradientBoostingRegressor(  random_state=0), param_grid, cv=kfold, n_jobs=-1,scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Fit the grid search to your data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best learning rate\n",
    "best_learning_rate = grid_search.best_params_['learning_rate']\n",
    "\n",
    "# Access the best regressor\n",
    "best_boosting_regressor = grid_search.best_estimator_\n",
    "\n",
    "# Access the best hyperparameters\n",
    "best_hyperparameters = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_boosting_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error = np.zeros_like(best_boosting_regressor.train_score_)\n",
    "\n",
    "for idx, y_ in enumerate(best_boosting_regressor.staged_predict(X_test)):\n",
    "    test_error[idx] = np.mean((y_test - y_)**2)\n",
    "\n",
    "plot_idx = np.arange(best_boosting_regressor.train_score_.shape[0]) \n",
    "\n",
    "ax = subplots(figsize=(8,8))[1]\n",
    "ax.plot(plot_idx,best_boosting_regressor.train_score_, 'b',label='Training')\n",
    "ax.plot(plot_idx, test_error ,'r',label='Test') \n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append metrics to the DataFrame\n",
    "metrics_df = metrics_df.append({'Model': type(best_boosting_regressor).__name__, 'MAE': mae, 'MSE': mse, 'R2': r2}, ignore_index=True)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances and corresponding feature names\n",
    "feature_importances = best_boosting_regressor.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a DataFrame to store feature names and their importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print or visualize the feature importances\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"85\"></a>\n",
    "<font color = 'blue'>\n",
    "### **8.5. Support Vector Machine (SVM)**\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to standardize the numerical data before using them to fit the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns= best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1= pd.DataFrame(StandardScaler().fit_transform(X_train[num_columns]),columns=num_columns,index=X_train.index)\n",
    "X_test1= pd.DataFrame(StandardScaler().fit_transform(X_test[num_columns]),columns=num_columns, index=X_test.index)\n",
    "\n",
    "X_train1 = pd.concat([X_train1, X_train[['drivetrain', 'fuel_type']]], axis=1)\n",
    "X_test1 = pd.concat([X_test1, X_test[['drivetrain', 'fuel_type']]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVR()  # You can specify kernel, C, gamma, etc.\n",
    "param_grid ={'C':[1], 'kernel':['linear']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create Cross-Validation Splitter and Perform Grid Search with Cross-Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validator = skm.KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "grid_search = skm.GridSearchCV(svm, param_grid, cv=cross_validator, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train1, y_train)  # X: feature matrix, y: target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_  # or random_search.best_estimator_\n",
    "best_params = grid_search.best_params_  # or random_search.best_params_\n",
    "best_score = grid_search.best_score_  # or random_search.best_score_\n",
    "print(\"The best SVR model: \", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluate the Model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=best_model.predict(X_test1)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append metrics to the DataFrame\n",
    "metrics_df = metrics_df.append({'Model': type(best_model).__name__, 'MAE': mae, 'MSE': mse, 'R2': r2}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a>\n",
    "<font color = 'blue'>\n",
    "### **8.6. Comparing Models:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **MAE** and **MSE**: Lower values are generally better for both MAE and MSE. If comparing two models, the one with the lower MAE or MSE is considered better in terms of accuracy.\n",
    "* <b>$R^2$</b>: Higher values of $R^2$ are desirable. $R^2$ represents the proportion of the variance explained by the model, so a higher $R^2$ indicates that the model is a better fit to the data. It ranges from 0 to 1, with higher values indicating better explanatory power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with three subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "# Bar width\n",
    "bar_width = 0.25\n",
    "\n",
    "# Positions on the y-axis for each model\n",
    "y_positions = np.arange(len(metrics_df['Model']))\n",
    "\n",
    "# Plotting MAE, MSE, and R2 in three subplots\n",
    "for ax, metric, color in zip(axes, ['MAE', 'MSE', 'R2'], ['blue', 'orange', 'green']):\n",
    "    ax.barh(y_positions, metrics_df[metric], height=bar_width, color=color, label=metric)\n",
    "    ax.set_title(metric)\n",
    "\n",
    "# Set common labels and title\n",
    "fig.suptitle('Model Evaluation Metrics')\n",
    "\n",
    "# Set labels and ticks for the y-axis\n",
    "axes[0].set_yticks(y_positions)\n",
    "axes[0].set_yticklabels(metrics_df['Model'])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower MAE or MSE is considered better in terms of accuracy and higher values of $R^2$ are desirable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Evaluation:</b>\n",
    "Based on the `metrics_df` and `plots`, we can see that `Gradient Boosting Regressor` is the best car price predictor.` Multiple Polynomial Regression` give a reasonable metrics. Therefore, we can use Gradient Boosting Regressor and Multiple Polynomial Regression to understand which features have the most significant impact on the predictions. This can provide insights into what aspects of the data are crucial for predicting car prices.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
